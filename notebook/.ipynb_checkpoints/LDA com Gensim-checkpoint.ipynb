{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/renato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# gerais\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Gensim\n",
    "import gensim, spacy\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "#plot\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"portuguese\"))\n",
    "stop_words.update(['que', 'até', 'esse', \n",
    "                    'essa', 'pro', 'pra',\n",
    "                    'oi', 'lá', 'blá', 'dos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>USUARIO</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>DATA_TWEET</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>meliiuza</td>\n",
       "      <td>RT @joshfeelsz: Meu Deus Eu tô em loop com ess...</td>\n",
       "      <td>2020-09-22 14:17:14</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Karine77379754</td>\n",
       "      <td>RT @majorjhs: eu nem fico mais surpresa com a ...</td>\n",
       "      <td>2020-09-22 14:17:19</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>EloaSuzi</td>\n",
       "      <td>RT @fabiofaria5555: PR @jairbolsonaro discursa...</td>\n",
       "      <td>2020-09-22 14:17:23</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>Djan00392004</td>\n",
       "      <td>RT @planalto: #AoVivo: Presidente @jairbolsona...</td>\n",
       "      <td>2020-09-22 14:17:22</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>barbaralustoza</td>\n",
       "      <td>biroliro falando de cristofobia na Assembleia ...</td>\n",
       "      <td>2020-09-22 14:17:22</td>\n",
       "      <td>portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID         USUARIO  \\\n",
       "0           1   2        meliiuza   \n",
       "1           9  11  Karine77379754   \n",
       "2          19  22        EloaSuzi   \n",
       "3          21  24    Djan00392004   \n",
       "4          22  25  barbaralustoza   \n",
       "\n",
       "                                               TWEET           DATA_TWEET  \\\n",
       "0  RT @joshfeelsz: Meu Deus Eu tô em loop com ess...  2020-09-22 14:17:14   \n",
       "1  RT @majorjhs: eu nem fico mais surpresa com a ...  2020-09-22 14:17:19   \n",
       "2  RT @fabiofaria5555: PR @jairbolsonaro discursa...  2020-09-22 14:17:23   \n",
       "3  RT @planalto: #AoVivo: Presidente @jairbolsona...  2020-09-22 14:17:22   \n",
       "4  biroliro falando de cristofobia na Assembleia ...  2020-09-22 14:17:22   \n",
       "\n",
       "     language  \n",
       "0  portuguese  \n",
       "1  portuguese  \n",
       "2  portuguese  \n",
       "3  portuguese  \n",
       "4  portuguese  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('../Dados coletados/Twitter_padronizado.csv', encoding='utf-8',  lineterminator='\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elementos_repetidos(lista):\n",
    "    nova_lista = []\n",
    "    for item in lista:\n",
    "        if item not in nova_lista:\n",
    "            nova_lista.append(item)\n",
    "    return nova_lista\n",
    "\n",
    "# remove special characters and digits\n",
    "def clean_tweet(tweet):\n",
    "    # remove os RT\n",
    "    tweet = re.sub(r'RT+', '', tweet) \n",
    "    \n",
    "    # remove as menções\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)  \n",
    "    \n",
    "    # remove links e alguns pontos\n",
    "    tweet = re.sub(r'kkk\\S+', '', tweet)\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    \n",
    "    # remove alguns caracteres\n",
    "    tweet  = re.sub(\"(\\\\d|\\\\W)+|\\w*\\d\\w*\",\" \",tweet )\n",
    "    tweet = ' '.join(s for s in tweet.split() if (not any(c.isdigit() for c in s)) and len(s) > 2)\n",
    "    tweet = tweet.replace(\"\\n\", \"\")\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nem fico mais surpresa com forma que essas premiações americanas tratam bts eles são maiores artistas geração',\n",
       " 'discursa agora assembleia geral organização das nações unidas onu brasil segue mostran',\n",
       " 'aovivo presidente faz discurso abertura assembleia geral organização das nações unidas onu',\n",
       " 'biroliro falando cristofobia assembleia geral onu claro igrejas cristãs são invadidas destruídas todos',\n",
       " 'discurso bolsonaro assembleia geral onu foi sucessão vergonhosa mentiras não restam dúvidas que ele',\n",
       " 'luto preço ser alfabetizado ouvir esse discurso bolsonaro assembleia geral onu saber que ele pres',\n",
       " 'bts participarar mais uma vez assembleia geral das nações unidas dia setembro grupo compartilhará uma men',\n",
       " 'que pesadelo presidente brasil enfileirando mentiras narrativas sem nem cabeça preconceitos teorias conspi',\n",
       " 'para quem não paraná não sabe que migué dolangue bolsonaro falando assembléia geral onu que']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets = []\n",
    "for w in range(len(df.TWEET)):\n",
    "  tweet = df['TWEET'].iloc[w]\n",
    "  tweet = clean_tweet(tweet)\n",
    "    \n",
    "  clean_tweets.append(tweet)\n",
    "\n",
    "#remover colunas repetidas\n",
    "clean_tweets = remove_elementos_repetidos(clean_tweets)\n",
    "clean_tweets[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['meu', 'deus', 'loop', 'com', 'esse', 'negocio', 'overthemoon'], ['nem', 'fico', 'mais', 'surpresa', 'com', 'forma', 'que', 'essas', 'premiacoes', 'americanas', 'tratam', 'bts', 'eles', 'sao', 'maiores', 'artistas', 'geracao'], ['discursa', 'agora', 'assembleia', 'geral', 'organizacao', 'das', 'nacoes', 'unidas', 'onu', 'brasil', 'segue', 'mostran'], ['aovivo', 'presidente', 'faz', 'discurso', 'abertura', 'assembleia', 'geral', 'organizacao', 'das', 'nacoes', 'unidas', 'onu'], ['biroliro', 'falando', 'cristofobia', 'assembleia', 'geral', 'onu', 'claro', 'igrejas', 'cristas', 'sao', 'invadidas', 'destruidas', 'todos'], ['discurso', 'bolsonaro', 'assembleia', 'geral', 'onu', 'foi', 'sucessao', 'vergonhosa', 'mentiras', 'nao', 'restam', 'duvidas', 'que', 'ele'], ['luto', 'preco', 'ser', 'alfabetizado', 'ouvir', 'esse', 'discurso', 'bolsonaro', 'assembleia', 'geral', 'onu', 'saber', 'que', 'ele', 'pres'], ['bts', 'participarar', 'mais', 'uma', 'vez', 'assembleia', 'geral', 'das', 'nacoes', 'unidas', 'dia', 'setembro', 'grupo', 'compartilhara', 'uma', 'men'], ['que', 'pesadelo', 'presidente', 'brasil', 'enfileirando', 'mentiras', 'narrativas', 'sem', 'nem', 'cabeca', 'preconceitos', 'teorias', 'conspi'], ['para', 'quem', 'nao', 'parana', 'nao', 'sabe', 'que', 'migue', 'dolangue', 'bolsonaro', 'falando', 'assembleia', 'geral', 'onu', 'que']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(clean_tweets))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['meu', 'deus', 'loop', 'com', 'esse', 'negocio', 'overthemoon']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)]]\n"
     ]
    }
   ],
   "source": [
    "data_words = data_words_bigrams\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('deus', 1), ('loop', 1), ('negocio', 1), ('overthemoon', 1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

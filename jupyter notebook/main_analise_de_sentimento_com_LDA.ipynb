{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/renatolopo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio import imread\n",
    "import warnings\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refinando stop word\n",
    "stop_words = set(stopwords.words(\"portuguese\"))\n",
    "stop_words.update(['que', 'até', 'esse', \n",
    "                    'essa', 'pro', 'pra',\n",
    "                    'oi', 'lá', 'blá', 'dos', 'esta'])\n",
    "const_words = [ 'de','a','o','que','e','do','da','em','um','para','e','com','nao','uma','os','no','vou','se','na','por','mais','as','dos','como','mas','foi','ao','ele','das','tem','a','seu','sua','ou','ser','quando','muito','ha','nos','ja','esta','eu','tambem','so','pelo','pela','ate','isso','ela','entre','era','depois','sem','mesmo','aos','ter','seus','quem','nas','me','esse','eles','estao','voce','tinha','foram','essa','num','nem','suas','meu','as','minha','tem','numa','pelos','elas','havia','seja','qual','sera','nos','tenho','lhe','deles','essas','esses','pelas','este','fosse','dele','tu','te','voces','vos','lhes','meus','minhas','teu','tua','teus','tuas','nosso','nossa','nossos','nossas','dela','delas','esta','estes','estas','aquele','aquela','aqueles','aquelas','isto','aquilo','estou','esta','estamos','estao','estive','esteve','estivemos','estiveram','estava','estavamos','estavam','estivera','estiveramos','esteja','estejamos','estejam','estivesse','estivessemos','estivessem','estiver','estivermos','estiverem','hei','ha','havemos','hao','houve','houvemos','houveram','houvera','houveramos','haja','hajamos','hajam','houvesse','houvessemos','houvessem','houver','houvermos','houverem','houverei','houvera','houveremos','houverao','houveria','houveriamos','houveriam','sou','somos','sao','era','eramos','eram','fui','foi','fomos','foram','fora','foramos','seja','sejamos','sejam','fosse','fossemos','fossem','for','formos','forem','serei','sera','seremos','serao','seria','seriamos','seriam','tenho','tem','temos','tem','tinha','tinhamos','tinham','tive','teve','tivemos','tiveram','tivera','tiveramos','tenha','tenhamos','tenham','tivesse','tivessemos','tivessem','tiver','tivermos','tiverem','terei','tera','teremos','terao','teria','teriamos','teriam','a', 'à', 'adeus', 'agora', 'aí', 'ainda', 'além', 'algo', 'alguém', 'algum', 'alguma', 'algumas', 'alguns', 'ali', 'ampla', 'amplas', 'amplo', 'amplos', 'ano', 'anos', 'ante', 'antes', 'ao', 'aos', 'apenas', 'apoio', 'após', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aqui', 'aquilo', 'área', 'as', 'às', 'assim', 'até', 'atrás', 'através', 'baixo', 'bastante', 'bem', 'boa', 'boas', 'bom', 'bons', 'breve', 'cá', 'cada', 'catorze', 'cedo', 'cento', 'certamente', 'certeza', 'cima', 'cinco', 'coisa', 'coisas', 'com', 'como', 'conselho', 'contra', 'contudo', 'custa', 'da', 'dá', 'dão', 'daquela', 'daquelas', 'daquele', 'daqueles', 'dar', 'das', 'de', 'debaixo', 'dela', 'delas', 'dele', 'deles', 'demais', 'dentro', 'depois', 'desde', 'dessa', 'dessas', 'desse', 'desses', 'desta', 'destas', 'deste', 'destes', 'deve', 'devem', 'devendo', 'dever', 'deverá', 'deverão', 'deveria', 'deveriam', 'devia', 'deviam', 'dez', 'dezanove', 'dezasseis', 'dezassete', 'dezoito', 'dia', 'diante', 'disse', 'disso', 'disto', 'dito', 'diz', 'dizem', 'dizer', 'do', 'dois', 'dos', 'doze', 'duas', 'dúvida', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'embora', 'enquanto', 'entre', 'era', 'eram', 'éramos', 'és', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estás', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estiveste', 'estivestes', 'estou', 'etc', 'eu', 'exemplo', 'faço', 'falta', 'favor', 'faz', 'fazeis', 'fazem', 'fazemos', 'fazendo', 'fazer', 'fazes', 'feita', 'feitas', 'feito', 'feitos', 'fez', 'fim', 'final', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'forma', 'formos', 'fosse', 'fossem', 'fôssemos', 'foste', 'fostes', 'fui', 'geral', 'grande', 'grandes', 'grupo', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'havia', 'hei', 'hoje', 'hora', 'horas', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'la', 'lá', 'lado', 'lhe', 'lhes', 'lo', 'local', 'logo', 'longe', 'lugar', 'maior', 'maioria', 'mais', 'mal', 'mas', 'máximo', 'me', 'meio', 'menor', 'menos', 'mês', 'meses', 'mesma', 'mesmas', 'mesmo', 'mesmos', 'meu', 'meus', 'mil', 'minha', 'minhas', 'momento', 'muita', 'muitas', 'muito', 'muitos', 'na', 'nada', 'não', 'naquela', 'naquelas', 'naquele', 'naqueles', 'nas', 'nem', 'nenhum', 'nenhuma', 'nessa', 'nessas', 'nesse', 'nesses', 'nesta', 'nestas', 'neste', 'nestes', 'ninguém', 'nível', 'no', 'noite', 'nome', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'nova', 'novas', 'nove', 'novo', 'novos', 'num', 'numa', 'número', 'nunca', 'o', 'obra', 'obrigada', 'obrigado', 'oitava', 'oitavo', 'oito', 'onde', 'ontem', 'onze', 'os', 'ou', 'outra', 'outras', 'outro', 'outros', 'para', 'parece', 'parte', 'partir', 'paucas', 'pela', 'pelas', 'pelo', 'pelos', 'pequena', 'pequenas', 'pequeno', 'pequenos', 'per', 'perante', 'perto', 'pode', 'pude', 'pôde', 'podem', 'podendo', 'poder', 'poderia', 'poderiam', 'podia', 'podiam', 'põe', 'põem', 'pois', 'ponto', 'pontos', 'por', 'porém', 'porque', 'porquê', 'posição', 'possível', 'possivelmente', 'posso', 'pouca', 'poucas', 'pouco', 'poucos', 'primeira', 'primeiras', 'primeiro', 'primeiros', 'própria', 'próprias', 'próprio', 'próprios', 'próxima', 'próximas', 'próximo', 'próximos', 'pude', 'puderam', 'quais', 'quáis', 'qual', 'quando', 'quanto', 'quantos', 'quarta', 'quarto', 'quatro', 'que', 'quê', 'quem', 'quer', 'quereis', 'querem', 'queremas', 'queres', 'quero', 'questão', 'quinta', 'quinto', 'quinze', 'relação', 'sabe', 'sabem', 'são', 'se', 'segunda', 'segundo', 'sei', 'seis', 'seja', 'sejam', 'sejamos', 'sem', 'sempre', 'sendo', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'sete', 'sétima', 'sétimo', 'seu', 'seus', 'sexta', 'sexto', 'si', 'sido', 'sim', 'sistema', 'só', 'sob', 'sobre', 'sois', 'somos', 'sou', 'sua', 'suas', 'tal', 'talvez', 'também', 'tampouco', 'tanta', 'tantas', 'tanto', 'tão', 'tarde', 'te', 'tem', 'tém', 'têm', 'temos', 'tendes', 'tendo', 'tenha', 'tenham', 'tenhamos', 'tenho', 'tens', 'ter', 'terá', 'terão', 'terceira', 'terceiro', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'ti', 'tido', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tiveste', 'tivestes', 'toda', 'todas', 'todavia', 'todo', 'todos', 'trabalho', 'três', 'treze', 'tu', 'tua', 'tuas', 'tudo', 'última', 'últimas', 'último', 'últimos', 'um', 'uma', 'umas', 'uns', 'vai', 'vais', 'vão', 'vários', 'vem', 'vêm', 'vendo', 'vens', 'ver', 'vez', 'vezes', 'viagem', 'vindo', 'vinte', 'vir', 'você', 'vocês', 'vos', 'vós', 'vossa', 'vossas', 'vosso', 'vossos', 'zero', 'the', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_' ]\n",
    "wrd = [w for w in const_words if w not in stop_words]\n",
    "# contem 593 stop words em portugues\n",
    "stop_words.update(wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "file_name = \"Twitter\"\n",
    "df = pd.read_csv(f'/home/renatolopo/notebooks/files/resultados final/{file_name}.csv',  encoding='utf-8',  lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters and digits\n",
    "def clean_noticia(noticia):\n",
    "   \n",
    "    # remove links e alguns pontos\n",
    "    noticia = re.sub(r'<img src=\"https\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'href\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'rel', \"\", noticia)\n",
    "    noticia = re.sub(r'nofollow\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'mixvale\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'target\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'_blank\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r'www\\S+', \"\", noticia)\n",
    "    noticia = re.sub(r\"http\\S+\", \"\", noticia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    \n",
    "    # remove alguns caracteres\n",
    "    noticia  = re.sub(\"(\\\\d|\\\\W)+|\\w*\\d\\w*\",\" \",noticia )\n",
    "    noticia = ' '.join(s for s in noticia.split() if (not any(c.isdigit() for c in s)) and len(s) > 2)\n",
    "    noticia = noticia.replace(\"\\n\", \"\")\n",
    "    \n",
    "    #remove stopwords\n",
    "    noticia = ' '.join([w for w in noticia.split() if w not in stop_words])\n",
    "    return noticia\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # remove os RT\n",
    "    tweet = re.sub(r'RT+', '', tweet) \n",
    "    \n",
    "    # remove as menções\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)  \n",
    "    \n",
    "    # remove links e alguns pontos\n",
    "    tweet = re.sub(r'kkk', '', tweet)\n",
    "    tweet = re.sub(r'kkk\\S+', '', tweet)\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    \n",
    "    # remove alguns caracteres\n",
    "    tweet  = re.sub(\"(\\\\d|\\\\W)+|\\w*\\d\\w*\",\" \",tweet )\n",
    "    tweet = ' '.join(s for s in tweet.split() if (not any(c.isdigit() for c in s)) and len(s) > 2)\n",
    "    tweet = tweet.replace(\"\\n\", \"\")\n",
    "    tweet = ' '.join([w for w in tweet.split() if w not in stop_words])\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156801\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "for w in range(len(df.SUMMARY)):\n",
    "  # seleciona o titulo caso não exista descrição  \n",
    "  if df['SUMMARY'].iloc[w] == 'nan' or df['SUMMARY'].iloc[w] == '-' or type(df['SUMMARY'].iloc[w]) !=\" <class 'str'>\":\n",
    "    noticia = df['TITLE'].iloc[w]\n",
    "  else:\n",
    "    noticia = df['SUMMARY'].iloc[w]\n",
    " \n",
    "  noticia = clean_noticia(str(noticia))\n",
    "  \n",
    "  clean_text.append(noticia)\n",
    "\n",
    "\n",
    "print(len(clean_text))\n",
    "#clean_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "for w in range(len(df.TWEET)):\n",
    "  tweet = df['TWEET'].iloc[w]\n",
    "  tweet = clean_tweet(tweet)\n",
    "    \n",
    "  clean_text.append(tweet)\n",
    "\n",
    "\n",
    "#clean_tweets[110:145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem de Tópicos LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = np.array(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# COUNT vectorizer\n",
    "tf_vectorizer = CountVectorizer(\n",
    "        min_df = 30,\n",
    "        max_df = 0.5,\n",
    "        max_features = 10000,\n",
    "        stop_words = stop_words, \n",
    "        ngram_range = (1,2)\n",
    "  )\n",
    "\n",
    "#transform\n",
    "vec_text = tf_vectorizer.fit_transform(clean_text)\n",
    "\n",
    "#returns a list of words.\n",
    "words = tf_vectorizer.get_feature_names()\n",
    "#print(clean_tweets)\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_topics(W, H, feature_names, documents, no_top_words, no_top_documents):\n",
    "    topicos = {}\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        topicos[f'{topic_idx+1}'] = \", \".join([feature_names[i]\n",
    "                for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "    return topicos\n",
    "\n",
    "        \n",
    "def display_topics(W, H, feature_names, documents, no_top_words, no_top_documents):\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"\\n--\\nTopic #{}: \".format(topic_idx + 1))\n",
    "        print(\", \".join([feature_names[i]\n",
    "                for i in topic.argsort()[:-no_top_words - 1:-1]]).upper())\n",
    "        top_d_idx = np.argsort(W[:,topic_idx])[::-1][0:no_top_documents]\n",
    "        for d in top_d_idx: \n",
    "          doc_data = df[['TITLE', 'SUMMARY']].iloc[d]\n",
    "          print(f'{doc_data[0]} -  \\t{W[d, topic_idx]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=15, \n",
    "                                learning_method='online', # 'online' equivale a minibatch no k-means\n",
    "                                random_state=0)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "lda.fit(vec_text)\n",
    "doc_topic_matrix = lda.transform(vec_text)\n",
    "\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicos = get_topics(doc_topic_matrix,\n",
    "               lda.components_, \n",
    "               words,\n",
    "               df,\n",
    "               15, \n",
    "               10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - governo, homem, prefeito, preso, candidatos, pix, eleição, ônibus, pensão, caso, empresas, recorde, homem preso, presos, concessão\n",
      "\n",
      "2 - paulo, mulher, carro, entenda, fica, acidente, zona, motorista, cnh, centro, fogo, juiz, mata, bate, covas\n",
      "\n",
      "3 - bolsonaro, morre, casa, saque, rio, janeiro, homem, jovem, conta, quase, causa, pesquisa, vítima, conheça, caminhão\n",
      "\n",
      "4 - covid, vacinação, país, posse, poderá, corpo, renda, crianças, criança, profissionais, social, educação, comércio, maternidade, bbb\n",
      "\n",
      "5 - fgts, caixa, anuncia, morto, cadastro, lança, aplicativo, tiros, brasileiro, moradores, cidades, cadastro único, mantém, vence, domingo\n",
      "\n",
      "6 - vacina, prefeitura, durante, novembro, vídeo, veja, campanha, direito, regras, hospital, mostra, dicas, uso, estados, empresa\n",
      "\n",
      "7 - volta, outubro, dezembro, vivo, santos, ministério, joão, cai, filho, público, governo, aulas, trabalhador, valores, pessoa\n",
      "\n",
      "8 - vídeos, cidade, região, quintafeira, sextafeira, mercado, edição, dados, porto, preto, jornal, campinas, brasileira, assista íntegra, fiscal\n",
      "\n",
      "9 - estado, chega, benefício, doença, sábado, doria, sobe, auxílio doença, setembro, quartafeira, vítimas, cresce, reality, terçafeira, campo\n",
      "\n",
      "10 - auxílio, emergencial, auxílio emergencial, receber, alta, dias, semana, recebe, valor, benefícios, câmara, digital, queda, projeto, prazo\n",
      "\n",
      "11 - casos, coronavírus, mortes, saúde, registra, eleições, presidente, deixa, lista, vacinas, pedido, whatsapp, minas, único, confirma\n",
      "\n",
      "12 - veja, milhões, morte, confira, vagas, programa, enem, alerta, abre, vitória, detran, pagar, internet, online, tempo\n",
      "\n",
      "13 - polícia, aposentadoria, suspeito, operação, preso, prende, drogas, natal, matar, suspeitos, civil, stf, rede, segurança, tráfico\n",
      "\n",
      "14 - família, eua, bolsa, justiça, bolsa família, trump, biden, pessoas, pagamento, pede, vida, salário, ação, china, aumento\n",
      "\n",
      "15 - inss, brasil, pandemia, saiba, seguro, desemprego, paraná, seguro desemprego, brasileiros, coronavac, dinheiro, aponta, anvisa, especial, plano\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, v in topicos.items():\n",
    "    print(f'{i} - {v}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que pega uma lista de palavras e um texto como entrada e conta quantas vezes as palavras da lista aparecem no texto\n",
    "def count_words(words, text):\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        for w in text.split():\n",
    "            if word == w:\n",
    "                counter+= 1\n",
    "    return counter\n",
    "\n",
    "# Função para classificar cada resumo em um tópico, verificando o tópico que contém mais palavras.\n",
    "# Para cada resumo, cria um dicionário {topic: qtd words da lista} e depois verifica qual é a chave no dicionário com o maior número, que será o número do tópico a ser adicionado a uma lista e devolvido.\n",
    "\n",
    "def assign_topic(topic, text):\n",
    "    assign = []\n",
    "    for row in text:\n",
    "        topic_counts = {}\n",
    "        for key, value in topic.items():\n",
    "            v = [x for x in value.split(',')]\n",
    "            topic_counts[key] = count_words(v, row) #use function previously created\n",
    "            \n",
    "        ma = max(topic_counts, key=lambda k: topic_counts[k])\n",
    "        if topic_counts[ma] == 0:\n",
    "            assign.append('null')\n",
    "        else:\n",
    "             assign.append(ma)\n",
    "       \n",
    "    return assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['null',\n",
       " 'null',\n",
       " '12',\n",
       " 'null',\n",
       " 'null',\n",
       " '10',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " '15',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " '11',\n",
       " 'null',\n",
       " '12',\n",
       " 'null',\n",
       " '15',\n",
       " '15',\n",
       " 'null',\n",
       " 'null',\n",
       " 'null',\n",
       " '12',\n",
       " 'null']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_topic(topicos, df['text'].sample(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A lista de tópicos que irão no dataframe\n",
    "topics_list = assign_topic(topicos, df.text)\n",
    "\n",
    "# Adicionando a coluna de tópicos ao dataframe\n",
    "df['topics'] = topics_list\n",
    "#df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "null    111692\n",
       "15        7695\n",
       "12        4318\n",
       "8         4000\n",
       "13        3882\n",
       "11        3579\n",
       "1         3556\n",
       "10        3363\n",
       "6         2321\n",
       "5         2309\n",
       "3         2173\n",
       "14        2087\n",
       "4         1848\n",
       "2         1623\n",
       "7         1289\n",
       "9         1066\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_termos(topic):\n",
    "    return topicos[str(topic)]\n",
    "\n",
    "topicos['null'] = 'null'\n",
    "df['termos'] = np.array([get_termos(topic) for topic in df['topics'].values.astype('U')])\n",
    "#df.sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise de sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dados de treino disponivel em https://www.kaggle.com/luisfredgs/imdb-ptbr\n",
    "dataset = pd.read_csv('./files/treino/imdb-reviews-pt-br.csv')\n",
    "df2 = pd.read_csv('./files/treino/Tweets_Mg.csv')\n",
    "# unir os dois df\n",
    "rm_df2 = [x for x in list(df2.columns) if x not in ['Text','Classificacao']]\n",
    "\n",
    "#deixa os dois df com o mesmo numero de colunas\n",
    "dataset = dataset.drop(columns=['text_en','id'])\n",
    "df2 = df2.drop(columns=rm_df2)\n",
    "\n",
    "#deixa as colunas de sentimentos igual a do outro df\n",
    "dataset['sentiment'] = dataset['sentiment'].str.replace('neg', 'Negativo')\n",
    "dataset['sentiment'] = dataset['sentiment'].str.replace('pos', 'Positivo')\n",
    "\n",
    "# concatena os dois df\n",
    "dataset.columns = ['Text', 'Polaridade']\n",
    "df2.columns = ['Text', 'Polaridade']\n",
    "dataset = pd.concat([dataset,df2])\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo\n",
    "text = dataset[\"Text\"].values\n",
    "classes = dataset[\"Polaridade\"].values\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_text = vectorizer.fit_transform(text)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_text, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada do modelo. Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1\n",
    "resultados = cross_val_predict(modelo, freq_text, classes, cv = 10)\n",
    "# acuracia\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificando os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo treinado\n",
    "# dado um texto, retorna sua polaridade\n",
    "def classifica(text):\n",
    "    text = [text]\n",
    "    freq_testes = vectorizer.transform(text)\n",
    "    return modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polaridade'] = np.array([classifica(text)[0] for text in df['TITLE'].values.astype('U')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "      <th>termos</th>\n",
       "      <th>polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83595</th>\n",
       "      <td>Polícia Civil prende grupo de traficantes com ...</td>\n",
       "      <td>Por meio de informações anônimas, o Grupo de D...</td>\n",
       "      <td>polícia civil prende traficantes quilos maconh...</td>\n",
       "      <td>13</td>\n",
       "      <td>polícia, aposentadoria, suspeito, operação, pr...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63950</th>\n",
       "      <td>Suposto cabrito maltratado é encontrado pela p...</td>\n",
       "      <td>A Polícia Civil foi chamada para atender uma s...</td>\n",
       "      <td>suposto cabrito maltratado encontrado polícia ...</td>\n",
       "      <td>13</td>\n",
       "      <td>polícia, aposentadoria, suspeito, operação, pr...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91722</th>\n",
       "      <td>Atingidos em Mariana querem CPI para investiga...</td>\n",
       "      <td>Entidade financiada por Vale e BHP é a respons...</td>\n",
       "      <td>atingidos mariana cpi investigar fundação renova</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54745</th>\n",
       "      <td>Teste do bafômetro de motorista que atropelou ...</td>\n",
       "      <td>Motorista foi autuado por homicídio culposo. E...</td>\n",
       "      <td>teste bafômetro motorista atropelou matou mili...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37057</th>\n",
       "      <td>Homem é preso após marcar encontro com menina ...</td>\n",
       "      <td>Polícia chegou ao local marcado pelo pedófilo ...</td>\n",
       "      <td>homem preso marcar encontro menina pais garota...</td>\n",
       "      <td>13</td>\n",
       "      <td>polícia, aposentadoria, suspeito, operação, pr...</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82169</th>\n",
       "      <td>Delegado envolvido em esquema ilegal em aeropo...</td>\n",
       "      <td>Policial colaborava para liberação de mercador...</td>\n",
       "      <td>delegado envolvido esquema ilegal aeroporto pe...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33565</th>\n",
       "      <td>Camilo Santana anuncia tablets para os estudan...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/dmjbYFne_LYYcW...</td>\n",
       "      <td>camilo santana anuncia tablets estudantes univ...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77173</th>\n",
       "      <td>EUA rejeitam proposta de Putin para renovar pa...</td>\n",
       "      <td>Governo norte-americano rejeita ideia do presi...</td>\n",
       "      <td>eua rejeitam proposta putin renovar pacto nuclear</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56582</th>\n",
       "      <td>Matrículas para cursos de bordado e panificaçã...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/ccFRoUNsT2DGTs...</td>\n",
       "      <td>matrículas cursos bordado panificação abertas ...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76410</th>\n",
       "      <td>BRDE atinge marco de mais de R$ 945 milhões em...</td>\n",
       "      <td>O Banco Regional de Desenvolvimento do Extremo...</td>\n",
       "      <td>brde atinge marco milhões contratos paraná</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58882</th>\n",
       "      <td>A guerra dos ‘supremáveis’ pela vaga de Celso ...</td>\n",
       "      <td>-</td>\n",
       "      <td>guerra supremáveis vaga celso mello começou</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66961</th>\n",
       "      <td>Clubes da Série A são favoráveis à paralisação...</td>\n",
       "      <td>Em postagens nas redes sociais, presidentes de...</td>\n",
       "      <td>clubes série favoráveis paralisação brasileirão</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34032</th>\n",
       "      <td>Salesforce vai comprar aplicativo Slack por ce...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/uw8NoaXUfTAn4S...</td>\n",
       "      <td>salesforce comprar aplicativo slack cerca bilhões</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16219</th>\n",
       "      <td>Data da prova do concurso público da Câmara Mu...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/5hWGlXIW_IacX-...</td>\n",
       "      <td>data prova concurso público câmara municipal a...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33130</th>\n",
       "      <td>Pedágios de 12 cidades da região têm reajuste ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/20ccqnrSoZmt-f...</td>\n",
       "      <td>pedágios cidades região reajuste tarifa terça</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116540</th>\n",
       "      <td>Putin parabeniza Joe Biden por vitória nas ele...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>putin parabeniza joe biden vitória eleições es...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94608</th>\n",
       "      <td>Campanha para alertar caminhoneiros sobre roub...</td>\n",
       "      <td>Até sexta-feira (13) serão montados 350 postos...</td>\n",
       "      <td>campanha alertar caminhoneiros roubo cargas co...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51766</th>\n",
       "      <td>Com pandemia, empresas e poder público reavali...</td>\n",
       "      <td>Data não é considerada feriado. Festas estão p...</td>\n",
       "      <td>pandemia empresas público reavaliam facultativ...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37032</th>\n",
       "      <td>Candidatos eleitos de Maceió serão diplomados ...</td>\n",
       "      <td>Pela primeira vez solenidade de diplomação ser...</td>\n",
       "      <td>candidatos eleitos maceió diplomados durante c...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145514</th>\n",
       "      <td>Com Biden, Brasil precisa ser pragmático nas r...</td>\n",
       "      <td>&lt;a href=\"https://www1.folha.uol.com.br/mundo/2...</td>\n",
       "      <td>biden brasil precisa pragmático ações comercia...</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108084</th>\n",
       "      <td>Indicados ao Gotham Awards dão início à corrid...</td>\n",
       "      <td>Nomadland, protagonizado por Frances McDormand...</td>\n",
       "      <td>indicados gotham awards início corrida oscar</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136542</th>\n",
       "      <td>Bar de Curitiba viraliza após festa de swing e...</td>\n",
       "      <td>Um bar de Curitiba viralizou após fazer uma fe...</td>\n",
       "      <td>bar curitiba viraliza festa swing pandemia</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145097</th>\n",
       "      <td>Brasileira é uma das vítimas do atentado à bas...</td>\n",
       "      <td>O consulado do Brasil em Paris confirmou que u...</td>\n",
       "      <td>brasileira vítimas atentado basílica nice frança</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151697</th>\n",
       "      <td>São Paulo confirma o primeiro caso de reinfecç...</td>\n",
       "      <td>A Secretaria Estadual da Saúde confirmou na no...</td>\n",
       "      <td>paulo confirma caso reinfecção coronavírus</td>\n",
       "      <td>2</td>\n",
       "      <td>paulo, mulher, carro, entenda, fica, acidente,...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>Cerca de 90% das lavouras de soja de MS estão ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/WSN-VII-3aTxqr...</td>\n",
       "      <td>cerca lavouras soja condições</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    TITLE  \\\n",
       "83595   Polícia Civil prende grupo de traficantes com ...   \n",
       "63950   Suposto cabrito maltratado é encontrado pela p...   \n",
       "91722   Atingidos em Mariana querem CPI para investiga...   \n",
       "54745   Teste do bafômetro de motorista que atropelou ...   \n",
       "37057   Homem é preso após marcar encontro com menina ...   \n",
       "82169   Delegado envolvido em esquema ilegal em aeropo...   \n",
       "33565   Camilo Santana anuncia tablets para os estudan...   \n",
       "77173   EUA rejeitam proposta de Putin para renovar pa...   \n",
       "56582   Matrículas para cursos de bordado e panificaçã...   \n",
       "76410   BRDE atinge marco de mais de R$ 945 milhões em...   \n",
       "58882   A guerra dos ‘supremáveis’ pela vaga de Celso ...   \n",
       "66961   Clubes da Série A são favoráveis à paralisação...   \n",
       "34032   Salesforce vai comprar aplicativo Slack por ce...   \n",
       "16219   Data da prova do concurso público da Câmara Mu...   \n",
       "33130   Pedágios de 12 cidades da região têm reajuste ...   \n",
       "116540  Putin parabeniza Joe Biden por vitória nas ele...   \n",
       "94608   Campanha para alertar caminhoneiros sobre roub...   \n",
       "51766   Com pandemia, empresas e poder público reavali...   \n",
       "37032   Candidatos eleitos de Maceió serão diplomados ...   \n",
       "145514  Com Biden, Brasil precisa ser pragmático nas r...   \n",
       "108084  Indicados ao Gotham Awards dão início à corrid...   \n",
       "136542  Bar de Curitiba viraliza após festa de swing e...   \n",
       "145097  Brasileira é uma das vítimas do atentado à bas...   \n",
       "151697  São Paulo confirma o primeiro caso de reinfecç...   \n",
       "45461   Cerca de 90% das lavouras de soja de MS estão ...   \n",
       "\n",
       "                                                  SUMMARY  \\\n",
       "83595   Por meio de informações anônimas, o Grupo de D...   \n",
       "63950   A Polícia Civil foi chamada para atender uma s...   \n",
       "91722   Entidade financiada por Vale e BHP é a respons...   \n",
       "54745   Motorista foi autuado por homicídio culposo. E...   \n",
       "37057   Polícia chegou ao local marcado pelo pedófilo ...   \n",
       "82169   Policial colaborava para liberação de mercador...   \n",
       "33565   <img src=\"https://s2.glbimg.com/dmjbYFne_LYYcW...   \n",
       "77173   Governo norte-americano rejeita ideia do presi...   \n",
       "56582   <img src=\"https://s2.glbimg.com/ccFRoUNsT2DGTs...   \n",
       "76410   O Banco Regional de Desenvolvimento do Extremo...   \n",
       "58882                                                   -   \n",
       "66961   Em postagens nas redes sociais, presidentes de...   \n",
       "34032   <img src=\"https://s2.glbimg.com/uw8NoaXUfTAn4S...   \n",
       "16219   <img src=\"https://s2.glbimg.com/5hWGlXIW_IacX-...   \n",
       "33130   <img src=\"https://s2.glbimg.com/20ccqnrSoZmt-f...   \n",
       "116540                                                NaN   \n",
       "94608   Até sexta-feira (13) serão montados 350 postos...   \n",
       "51766   Data não é considerada feriado. Festas estão p...   \n",
       "37032   Pela primeira vez solenidade de diplomação ser...   \n",
       "145514  <a href=\"https://www1.folha.uol.com.br/mundo/2...   \n",
       "108084  Nomadland, protagonizado por Frances McDormand...   \n",
       "136542  Um bar de Curitiba viralizou após fazer uma fe...   \n",
       "145097  O consulado do Brasil em Paris confirmou que u...   \n",
       "151697  A Secretaria Estadual da Saúde confirmou na no...   \n",
       "45461   <img src=\"https://s2.glbimg.com/WSN-VII-3aTxqr...   \n",
       "\n",
       "                                                     text topics  \\\n",
       "83595   polícia civil prende traficantes quilos maconh...     13   \n",
       "63950   suposto cabrito maltratado encontrado polícia ...     13   \n",
       "91722    atingidos mariana cpi investigar fundação renova   null   \n",
       "54745   teste bafômetro motorista atropelou matou mili...   null   \n",
       "37057   homem preso marcar encontro menina pais garota...     13   \n",
       "82169   delegado envolvido esquema ilegal aeroporto pe...   null   \n",
       "33565   camilo santana anuncia tablets estudantes univ...   null   \n",
       "77173   eua rejeitam proposta putin renovar pacto nuclear   null   \n",
       "56582   matrículas cursos bordado panificação abertas ...   null   \n",
       "76410          brde atinge marco milhões contratos paraná   null   \n",
       "58882         guerra supremáveis vaga celso mello começou   null   \n",
       "66961     clubes série favoráveis paralisação brasileirão   null   \n",
       "34032   salesforce comprar aplicativo slack cerca bilhões   null   \n",
       "16219   data prova concurso público câmara municipal a...   null   \n",
       "33130       pedágios cidades região reajuste tarifa terça   null   \n",
       "116540  putin parabeniza joe biden vitória eleições es...   null   \n",
       "94608   campanha alertar caminhoneiros roubo cargas co...   null   \n",
       "51766   pandemia empresas público reavaliam facultativ...   null   \n",
       "37032   candidatos eleitos maceió diplomados durante c...   null   \n",
       "145514  biden brasil precisa pragmático ações comercia...   null   \n",
       "108084       indicados gotham awards início corrida oscar   null   \n",
       "136542         bar curitiba viraliza festa swing pandemia   null   \n",
       "145097   brasileira vítimas atentado basílica nice frança   null   \n",
       "151697         paulo confirma caso reinfecção coronavírus      2   \n",
       "45461                       cerca lavouras soja condições   null   \n",
       "\n",
       "                                                   termos polaridade  \n",
       "83595   polícia, aposentadoria, suspeito, operação, pr...   Positivo  \n",
       "63950   polícia, aposentadoria, suspeito, operação, pr...   Negativo  \n",
       "91722                                                null   Positivo  \n",
       "54745                                                null   Positivo  \n",
       "37057   polícia, aposentadoria, suspeito, operação, pr...   Positivo  \n",
       "82169                                                null   Positivo  \n",
       "33565                                                null   Positivo  \n",
       "77173                                                null   Positivo  \n",
       "56582                                                null     Neutro  \n",
       "76410                                                null   Positivo  \n",
       "58882                                                null   Positivo  \n",
       "66961                                                null   Positivo  \n",
       "34032                                                null   Negativo  \n",
       "16219                                                null   Positivo  \n",
       "33130                                                null   Positivo  \n",
       "116540                                               null   Positivo  \n",
       "94608                                                null   Positivo  \n",
       "51766                                                null   Positivo  \n",
       "37032                                                null   Positivo  \n",
       "145514                                               null   Positivo  \n",
       "108084                                               null   Positivo  \n",
       "136542                                               null   Negativo  \n",
       "145097                                               null   Positivo  \n",
       "151697  paulo, mulher, carro, entenda, fica, acidente,...   Negativo  \n",
       "45461                                                null   Negativo  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'/home/renatolopo/notebooks/files/resultados final/resultado_{file_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}